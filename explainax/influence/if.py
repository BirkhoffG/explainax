# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/api/influence.if.ipynb.

# %% auto 0
__all__ = ['BaseIF', 'flatten', 'leaves_to_jndarray', 'hvp', 'hessian']

# %% ../../nbs/api/influence.if.ipynb 1
from ..imports import *
from .base import Influence
from sklearn.datasets import make_classification
from sklearn import linear_model
import haiku as hk
import jax_dataloader as jdl

# %% ../../nbs/api/influence.if.ipynb 2
class BaseIF(Influence):
    def __init__(
        self, 
        func: Callable, # A black-box function to be explained
        params, # Parameters of the black-box function
        train_dataset: Tuple[Array, Array], # Training dataset
        additional_func_args: Dict = None, # Additional arguments for the black-box function
        input_paramter_name: str = "x", # Name of the input parameter for the black-box function
        **kwargs
    ):
        super().__init__(func, additional_func_args, train_dataset)

    def ihvp(self, vec: Array) -> Array:
        raise NotImplementedError
    

# %% ../../nbs/api/influence.if.ipynb 3
# https://github.com/pomonam/jax-influence/blob/main/jax_influence/utils.py
def flatten(params):
    return jax.flatten_util.ravel_pytree(params)[0]

def leaves_to_jndarray(pytree):
    """Converts leaves of pytree to jax.numpy arrays."""
    return jax.tree_map(jnp.array, pytree)

@partial(jit, static_argnums=(0,))
def hvp(f, primals, tangents):
    return jax.jvp(jax.grad(f), primals, tangents)[1]

def hessian(f):
     return jax.jit(jax.jacfwd(jax.jacrev(f)))
