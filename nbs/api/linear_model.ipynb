{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from explainax.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def l2_loss(x1, x2, weights=None):\n",
    "    if weights is None:\n",
    "        return optax.l2_loss(x1, x2)\n",
    "    else:\n",
    "        return jnp.sum((weights / optax.safe_norm(weights, ord=1)) * jnp.square(x1 - x2)) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _init_train_fn(\n",
    "    X: jnp.ndarray, # Input data\n",
    "    y: jnp.ndarray, # Target data\n",
    "    fit_bias: bool = True, # Fit bias term\n",
    "    seed: int = 42, # Random seed\n",
    "):  \n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    n_samples, n_features = X.shape\n",
    "    rng, w_key, b_key = jax.random.split(rng, 3)\n",
    "    w = jax.random.normal(w_key, (n_features,))\n",
    "    if fit_bias:\n",
    "        b = jax.random.normal(b_key, (1,))\n",
    "    else:\n",
    "        b = jnp.zeros(1)\n",
    "    params = dict(w=w, b=b)\n",
    "    return params\n",
    "\n",
    "def calculate_loss(\n",
    "    params: Dict[str, jnp.ndarray],\n",
    "    batch: Tuple[Array, Array, Array],\n",
    "    loss_fn: Callable,\n",
    "    reg_term: int = None,\n",
    "    alpha: float = 1.0\n",
    "):\n",
    "    \"\"\"Calculate the loss for a batch of data.\"\"\"\n",
    "    w, b = params[\"w\"], params[\"b\"]\n",
    "    X, y, weights = batch\n",
    "    y_pred = jnp.dot(X, w) + b\n",
    "    loss = loss_fn(y, y_pred, weights)\n",
    "    if reg_term is not None:\n",
    "        reg = jnp.linalg.norm(w, ord=reg_term)\n",
    "        loss += jnp.mean(reg) * alpha\n",
    "    return loss\n",
    "\n",
    "def sgd_train_linear_model(\n",
    "    X: jnp.ndarray, # Input data. Shape: `(N, k)`\n",
    "    y: jnp.ndarray, # Target data. Shape: `(N,)` or `(N, 1)`\n",
    "    weights: jnp.ndarray = None, # Initial weights. Shape: `(N,)`\n",
    "    lr: float = 0.01, # Learning rate\n",
    "    n_epochs: int = 100, # Number of epochs\n",
    "    batch_size: int = 32, # Batch size\n",
    "    seed: int = 42, # Random seed\n",
    "    loss_fn: Callable = l2_loss, # Loss function\n",
    "    reg_term: int = None, # Regularization term\n",
    "    alpha: float = 1.0, # Regularization strength\n",
    "    fit_bias: bool = True, # Fit bias term\n",
    ") -> Tuple[np.ndarray, np.ndarray]: # The trained weights and bias\n",
    "    \"\"\"Train a linear model using SGD.\"\"\"\n",
    "\n",
    "    @jax.jit\n",
    "    def sgd_step(params, opt_state, batch):\n",
    "        \"\"\"Perform a single SGD step.\"\"\"\n",
    "        grads = jax.grad(calculate_loss)(params, batch, loss_fn, reg_term, alpha)\n",
    "        updates, opt_state = opt.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        return params, opt_state\n",
    "\n",
    "    # TODO: Check shapes of X and y\n",
    "    n_samples = X.shape[0]\n",
    "    params = _init_train_fn(X, y, fit_bias, seed)\n",
    "    opt = optax.sgd(lr)\n",
    "    opt_state = opt.init(params)\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            X_batch = X[i : i + batch_size]\n",
    "            y_batch = y[i : i + batch_size]\n",
    "            w_batch = weights[i : i + batch_size] if weights is not None else None\n",
    "            params, opt_state = sgd_step(params, opt_state, (X_batch, y_batch, w_batch))\n",
    "    return params[\"w\"], params[\"b\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseEstimator:\n",
    "    def __init__(self):\n",
    "        ...\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LinearModel(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        intercept: bool = True,\n",
    "        trainer_fn: Callable=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.fit_bias = intercept\n",
    "        self.trainer_fn = sgd_train_linear_model if trainer_fn is None else trainer_fn\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        X: jnp.ndarray, \n",
    "        y: jnp.ndarray,\n",
    "        weights: jnp.ndarray = None,\n",
    "        **kwargs,\n",
    "    ) -> LinearModel:\n",
    "        self.coef_, self.intercept_ = self.trainer_fn(\n",
    "            X, y, weights, fit_bias=self.fit_bias, **kwargs)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Lasso(LinearModel):\n",
    "    def __init__(self, alpha: float = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X: jnp.ndarray, y: jnp.ndarray, weights: jnp.ndarray = None, **kwargs) -> LinearModel:\n",
    "        return super().fit(X, y, weights, reg_term=1, alpha=self.alpha, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Ridge(LinearModel):\n",
    "    def __init__(self, alpha: float = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X: jnp.ndarray, y: jnp.ndarray, weights: jnp.ndarray = None, **kwargs) -> LinearModel:\n",
    "        return super().fit(X, y, weights, reg_term=2, alpha=self.alpha, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=500, n_features=20)\n",
    "w = np.ones(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.08898669e-14,  3.10345763e+00, -3.40252413e-14, -1.17304952e-14,\n",
       "         1.63301547e+01, -1.12741395e-14,  3.89375096e-14,  2.12155613e+01,\n",
       "         1.87952565e-15, -2.45710044e-14, -5.12493483e-15,  3.53391521e+01,\n",
       "         2.49617925e+01,  1.92548415e-15,  1.15489565e+01,  6.26240704e+00,\n",
       "         2.80896941e+01,  3.32831479e+01,  7.02041648e-15,  3.46566155e+01]),\n",
       " 8.881784197001252e-16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_lm = LinearRegression()\n",
    "sk_lm.fit(X, y)\n",
    "sk_lm.coef_, sk_lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([ 8.38563865e-05,  3.10347271e+00,  2.50895084e-07, -7.12871915e-05,\n",
       "         1.63300648e+01,  2.79284559e-05,  1.49981890e-04,  2.12155819e+01,\n",
       "        -4.31869266e-05, -1.74582556e-06, -1.05994470e-04,  3.53389740e+01,\n",
       "         2.49617939e+01,  6.73230243e-05,  1.15488825e+01,  6.26239347e+00,\n",
       "         2.80897846e+01,  3.32830086e+01,  3.86646097e-05,  3.46564369e+01],      dtype=float32),\n",
       " Array([-6.177535e-05], dtype=float32))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearModel()\n",
    "lm.fit(X, y)\n",
    "lm.fit(X, y, w)\n",
    "lm.coef_, lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(sk_lm.coef_, lm.coef_, atol=5e-3)\n",
    "assert np.allclose(sk_lm.intercept_, lm.intercept_, atol=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([ 6.7087787e-04,  6.7190990e+00,  7.1662598e+01,\n",
       "               7.4942748e-04, -5.4690341e-04, -1.1745903e-03,\n",
       "               4.2832729e+01,  6.7359884e-04, -1.9092231e-04,\n",
       "               3.2343441e+01, -2.1547372e-04,  7.0898727e+01,\n",
       "               3.2021362e+01,  9.4644330e-04,  2.6314874e+00,\n",
       "               6.8846603e+01,  8.2106552e+01, -2.2809652e-03,\n",
       "              -9.7414968e-04,  6.9408112e+01], dtype=float32),\n",
       " DeviceArray([0.03017059], dtype=float32))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "lasso.fit(X, y, w)\n",
    "lasso.coef_, lasso.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([ 2.2781775e-03,  6.8124046e+00,  7.1715286e+01,\n",
       "               2.9025278e-03,  3.1277947e-03, -1.9458444e-03,\n",
       "               4.2912235e+01,  2.3261304e-03,  4.7600130e-03,\n",
       "               3.2431641e+01,  4.1142856e-03,  7.0952370e+01,\n",
       "               3.2105915e+01, -2.5508574e-03,  2.7339778e+00,\n",
       "               6.8915466e+01,  8.2148575e+01, -8.6568939e-03,\n",
       "               7.1830135e-03,  6.9459007e+01], dtype=float32),\n",
       " DeviceArray([0.00411766], dtype=float32))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.1)\n",
    "ridge.fit(X, y)\n",
    "ridge.fit(X, y, w)\n",
    "ridge.coef_, ridge.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
